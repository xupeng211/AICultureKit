#!/usr/bin/env python3
"""
æ€§èƒ½åˆ†æå™¨
åˆ†æä»£ç ä¸­å¯èƒ½çš„æ€§èƒ½é—®é¢˜å¹¶æä¾›ä¼˜åŒ–å»ºè®®
"""

import ast
from pathlib import Path
from typing import Any


class PerformanceAnalyzer:
    """æ€§èƒ½åˆ†æå™¨"""

    def __init__(self, project_path: Path = None):
        """__init__å‡½æ•°"""
        self.project_path = project_path or Path.cwd()
        self.issues = []

    def analyze_file(self, file_path: Path) -> list[dict[str, Any]]:
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„æ€§èƒ½é—®é¢˜"""
        try:
            content = file_path.read_text(encoding="utf-8")
            tree = ast.parse(content)
            lines = content.split("\n")

            file_issues = []

            # åˆ†æå„ç§æ€§èƒ½é—®é¢˜
            file_issues.extend(self.check_large_functions(tree, file_path))
            file_issues.extend(self.check_nested_loops(tree, file_path))
            file_issues.extend(self.check_string_concatenation(tree, file_path, lines))
            file_issues.extend(self.check_inefficient_patterns(tree, file_path, lines))
            file_issues.extend(self.check_file_size(file_path, lines))

            return file_issues

        except Exception as e:
            return [
                {
                    "file": str(file_path),
                    "line": 0,
                    "issue": "parse_error",
                    "description": f"æ— æ³•è§£ææ–‡ä»¶: {e}",
                    "suggestion": "æ£€æŸ¥è¯­æ³•é”™è¯¯",
                    "severity": "error",
                }
            ]

    def check_large_functions(self, tree: ast.AST, file_path: Path) -> list[dict[str, Any]]:
        """æ£€æŸ¥è¿‡å¤§çš„å‡½æ•°"""
        issues = []

        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                # è®¡ç®—å‡½æ•°è¡Œæ•°
                if hasattr(node, "end_lineno") and node.end_lineno:
                    func_lines = node.end_lineno - node.lineno + 1

                    if func_lines > 50:
                        issues.append(
                            {
                                "file": str(file_path),
                                "line": node.lineno,
                                "issue": "large_function",
                                "description": f"å‡½æ•° '{node.name}' è¿‡å¤§ ({func_lines} è¡Œ)",
                                "suggestion": "è€ƒè™‘å°†å¤§å‡½æ•°æ‹†åˆ†ä¸ºå¤šä¸ªå°å‡½æ•°",
                                "severity": "warning" if func_lines < 100 else "error",
                            }
                        )

        return issues

    def check_nested_loops(self, tree: ast.AST, file_path: Path) -> list[dict[str, Any]]:
        """æ£€æŸ¥åµŒå¥—å¾ªç¯"""
        issues = []

        def count_nested_loops(node, depth=0):
            """count_nested_loopså‡½æ•°"""
            if isinstance(node, (ast.For, ast.While)):
                depth += 1
                if depth > 2:
                    issues.append(
                        {
                            "file": str(file_path),
                            "line": node.lineno,
                            "issue": "deep_nested_loops",
                            "description": f"æ·±åº¦åµŒå¥—å¾ªç¯ (æ·±åº¦: {depth})",
                            "suggestion": "è€ƒè™‘ä½¿ç”¨å‡½æ•°æˆ–ç”Ÿæˆå™¨æ¥å‡å°‘åµŒå¥—",
                            "severity": "warning",
                        }
                    )

            for child in ast.iter_child_nodes(node):
                count_nested_loops(child, depth)

        count_nested_loops(tree)
        return issues

    def check_string_concatenation(
        self, tree: ast.AST, file_path: Path, lines: list[str]
    ) -> list[dict[str, Any]]:
        """æ£€æŸ¥å­—ç¬¦ä¸²æ‹¼æ¥æ€§èƒ½é—®é¢˜"""
        issues = []

        for node in ast.walk(tree):
            if isinstance(node, ast.BinOp) and isinstance(node.op, ast.Add):
                # æ£€æŸ¥æ˜¯å¦æ˜¯å­—ç¬¦ä¸²æ‹¼æ¥
                if (
                    isinstance(node.left, ast.Str)
                    or isinstance(node.right, ast.Str)
                    or (isinstance(node.left, ast.Constant) and isinstance(node.left.value, str))
                    or (isinstance(node.right, ast.Constant) and isinstance(node.right.value, str))
                ):
                    # æ£€æŸ¥æ˜¯å¦åœ¨å¾ªç¯ä¸­
                    parent = node
                    in_loop = False
                    while hasattr(parent, "parent"):
                        parent = parent.parent
                        if isinstance(parent, (ast.For, ast.While)):
                            in_loop = True
                            break

                    if in_loop:
                        issues.append(
                            {
                                "file": str(file_path),
                                "line": node.lineno,
                                "issue": "string_concat_in_loop",
                                "description": "å¾ªç¯ä¸­çš„å­—ç¬¦ä¸²æ‹¼æ¥å¯èƒ½å½±å“æ€§èƒ½",
                                "suggestion": "è€ƒè™‘ä½¿ç”¨åˆ—è¡¨æ”¶é›†å­—ç¬¦ä¸²ï¼Œæœ€åç”¨join()è¿æ¥",
                                "severity": "warning",
                            }
                        )

        return issues

    def check_inefficient_patterns(
        self, tree: ast.AST, file_path: Path, lines: list[str]
    ) -> list[dict[str, Any]]:
        """æ£€æŸ¥ä½æ•ˆçš„ä»£ç æ¨¡å¼"""
        issues = []

        for i, line in enumerate(lines, 1):
            line_stripped = line.strip()

            # æ£€æŸ¥ä½æ•ˆçš„åˆ—è¡¨æ“ä½œ
            if "for" in line_stripped and "in range(len(" in line_stripped:
                issues.append(
                    {
                        "file": str(file_path),
                        "line": i,
                        "issue": "inefficient_iteration",
                        "description": "ä½¿ç”¨range(len())è¿›è¡Œè¿­ä»£",
                        "suggestion": "è€ƒè™‘ç›´æ¥è¿­ä»£åˆ—è¡¨æˆ–ä½¿ç”¨enumerate()",
                        "severity": "info",
                    }
                )

            # æ£€æŸ¥é‡å¤çš„å­—å…¸æŸ¥æ‰¾
            if line_stripped.count("[") > 2 and "dict" in line_stripped.lower():
                issues.append(
                    {
                        "file": str(file_path),
                        "line": i,
                        "issue": "repeated_dict_lookup",
                        "description": "å¯èƒ½å­˜åœ¨é‡å¤çš„å­—å…¸æŸ¥æ‰¾",
                        "suggestion": "è€ƒè™‘å°†æŸ¥æ‰¾ç»“æœç¼“å­˜åˆ°å˜é‡ä¸­",
                        "severity": "info",
                    }
                )

        return issues

    def check_file_size(self, file_path: Path, lines: list[str]) -> list[dict[str, Any]]:
        """æ£€æŸ¥æ–‡ä»¶å¤§å°"""
        issues = []
        line_count = len(lines)

        if line_count > 500:
            issues.append(
                {
                    "file": str(file_path),
                    "line": 0,
                    "issue": "large_file",
                    "description": f"æ–‡ä»¶è¿‡å¤§ ({line_count} è¡Œ)",
                    "suggestion": "è€ƒè™‘å°†å¤§æ–‡ä»¶æ‹†åˆ†ä¸ºå¤šä¸ªæ¨¡å—",
                    "severity": "warning" if line_count < 1000 else "error",
                }
            )

        return issues

    def analyze_all_files(self) -> dict[str, Any]:
        """åˆ†ææ‰€æœ‰Pythonæ–‡ä»¶"""
        all_issues = []
        stats = {"files_analyzed": 0, "issues_found": 0}

        for py_file in self.project_path.rglob("*.py"):
            # è·³è¿‡è™šæ‹Ÿç¯å¢ƒå’Œéšè—ç›®å½•
            if any(
                part.startswith(".") or part in ["venv", "__pycache__", "build", "dist"]
                for part in py_file.parts
            ):
                continue

            # è·³è¿‡æ¨¡æ¿æ–‡ä»¶
            if "{{" in str(py_file) or "}}" in str(py_file):
                continue

            stats["files_analyzed"] += 1
            file_issues = self.analyze_file(py_file)
            all_issues.extend(file_issues)

            if file_issues:
                print(f"ğŸ“ {py_file}: å‘ç° {len(file_issues)} ä¸ªæ€§èƒ½é—®é¢˜")

        stats["issues_found"] = len(all_issues)

        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
        by_severity = {"error": [], "warning": [], "info": []}
        for issue in all_issues:
            by_severity[issue["severity"]].append(issue)

        return {"stats": stats, "issues": all_issues, "by_severity": by_severity}

    def generate_report(self, analysis_result: dict[str, Any]) -> str:
        """ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š"""
        stats = analysis_result["stats"]
        by_severity = analysis_result["by_severity"]

        report = f"""
ğŸš€ AICultureKit æ€§èƒ½åˆ†ææŠ¥å‘Š
{'='*50}

ğŸ“Š åˆ†æç»Ÿè®¡:
  - åˆ†ææ–‡ä»¶æ•°: {stats['files_analyzed']}
  - å‘ç°é—®é¢˜æ•°: {stats['issues_found']}
  - é”™è¯¯: {len(by_severity['error'])}
  - è­¦å‘Š: {len(by_severity['warning'])}
  - ä¿¡æ¯: {len(by_severity['info'])}

"""

        # æŒ‰ä¸¥é‡ç¨‹åº¦æ˜¾ç¤ºé—®é¢˜
        for severity in ["error", "warning", "info"]:
            issues = by_severity[severity]
            if not issues:
                continue

            emoji = {"error": "ğŸ”´", "warning": "ğŸŸ¡", "info": "ğŸ”µ"}[severity]
            report += f"\n{emoji} {severity.upper()} ({len(issues)}ä¸ª):\n"

            # æŒ‰é—®é¢˜ç±»å‹åˆ†ç»„
            by_type = {}
            for issue in issues:
                issue_type = issue["issue"]
                if issue_type not in by_type:
                    by_type[issue_type] = []
                by_type[issue_type].append(issue)

            for issue_type, type_issues in by_type.items():
                report += f"\n  ğŸ“‹ {issue_type} ({len(type_issues)}ä¸ª):\n"
                for issue in type_issues[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    report += f"    - {issue['file']}:{issue['line']} - {issue['description']}\n"
                    report += f"      ğŸ’¡ {issue['suggestion']}\n"

                if len(type_issues) > 3:
                    report += f"    ... è¿˜æœ‰ {len(type_issues) - 3} ä¸ªç±»ä¼¼é—®é¢˜\n"

        # ä¼˜åŒ–å»ºè®®
        report += """

ğŸ’¡ ä¼˜åŒ–å»ºè®®:
  1. ä¼˜å…ˆä¿®å¤é”™è¯¯çº§åˆ«çš„é—®é¢˜
  2. å°†å¤§æ–‡ä»¶æ‹†åˆ†ä¸ºå¤šä¸ªæ¨¡å—
  3. é‡æ„è¿‡å¤§çš„å‡½æ•°
  4. ä¼˜åŒ–å¾ªç¯ä¸­çš„å­—ç¬¦ä¸²æ“ä½œ
  5. å‡å°‘æ·±åº¦åµŒå¥—çš„å¾ªç¯

ğŸ“ˆ é¢„æœŸæ”¶ç›Š:
  - æé«˜ä»£ç å¯ç»´æŠ¤æ€§
  - å‡å°‘å†…å­˜ä½¿ç”¨
  - æå‡è¿è¡Œæ€§èƒ½
  - æ”¹å–„ä»£ç å¯è¯»æ€§
"""

        return report


def main() -> None:
    """ä¸»å‡½æ•°"""
    analyzer = PerformanceAnalyzer()

    print("ğŸš€ å¼€å§‹æ€§èƒ½åˆ†æ...")
    result = analyzer.analyze_all_files()

    print("\n" + "=" * 50)
    report = analyzer.generate_report(result)
    print(report)

    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    report_file = Path("performance_analysis_report.md")
    report_file.write_text(report, encoding="utf-8")
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


if __name__ == "__main__":
    main()
