#!/usr/bin/env python3
"""æ¶æ„è®¾è®¡åˆ†æå·¥å…·"""

import ast
from collections import defaultdict
from dataclasses import dataclass
from pathlib import Path
from typing import Any


@dataclass
class ArchitectureIssue:
    """æ¶æ„é—®é¢˜"""

    file_path: str
    issue_type: str
    severity: str
    description: str
    suggestion: str
    details: dict[str, Any] = None


class ArchitectureAnalyzer:
    """æ¶æ„åˆ†æå™¨"""

    def __init__(self, project_path: Path):
        """__init__å‡½æ•°"""
        self.project_path = project_path
        self.issues = []
        self.dependencies = defaultdict(set)  # ç®€åŒ–çš„ä¾èµ–å›¾
        self.module_info = {}

    def analyze_architecture(self) -> dict[str, Any]:
        """åˆ†æé¡¹ç›®æ¶æ„"""
        print("ğŸ—ï¸ å¼€å§‹æ¶æ„è®¾è®¡åˆ†æ...")

        # 1. åˆ†ææ¨¡å—ä¾èµ–å…³ç³»
        self._analyze_dependencies()

        # 2. æ£€æŸ¥å¾ªç¯ä¾èµ–
        self._check_circular_dependencies()

        # 3. åˆ†ææ¨¡å—è€¦åˆåº¦
        self._analyze_coupling()

        # 4. æ£€æŸ¥å•ä¸€èŒè´£åŸåˆ™
        self._check_single_responsibility()

        # 5. åˆ†ææ¥å£è®¾è®¡
        self._analyze_interfaces()

        # 6. æ£€æŸ¥ä¾èµ–å€’ç½®
        self._check_dependency_inversion()

        return self._generate_architecture_report()

    def _analyze_dependencies(self):
        """åˆ†ææ¨¡å—ä¾èµ–å…³ç³»"""
        python_files = list(self.project_path.rglob("*.py"))

        for file_path in python_files:
            if self._should_skip_file(file_path):
                continue

            try:
                with open(file_path, encoding="utf-8") as f:
                    content = f.read()
                    tree = ast.parse(content)

                module_name = self._get_module_name(file_path)
                imports = self._extract_imports(tree)

                self.module_info[module_name] = {
                    "file_path": str(file_path),
                    "imports": imports,
                    "classes": self._extract_classes(tree),
                    "functions": self._extract_functions(tree),
                    "lines_of_code": len(content.split("\n")),
                }

                # æ„å»ºä¾èµ–å…³ç³»
                for imported_module in imports:
                    if imported_module.startswith("aiculture"):
                        self.dependencies[module_name].add(imported_module)

            except (SyntaxError, UnicodeDecodeError):
                continue

    def _check_circular_dependencies(self):
        """æ£€æŸ¥å¾ªç¯ä¾èµ–ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        # ç®€å•çš„å¾ªç¯ä¾èµ–æ£€æŸ¥
        for module_a in self.dependencies:
            for module_b in self.dependencies[module_a]:
                if (
                    module_b in self.dependencies
                    and module_a in self.dependencies[module_b]
                ):
                    # å‘ç°åŒå‘ä¾èµ–
                    self.issues.append(
                        ArchitectureIssue(
                            file_path=f"{module_a} <-> {module_b}",
                            issue_type="circular_dependency",
                            severity="high",
                            description=f"å‘ç°å¾ªç¯ä¾èµ–: {module_a} <-> {module_b}",
                            suggestion="é‡æ„ä»£ç ä»¥æ¶ˆé™¤å¾ªç¯ä¾èµ–ï¼Œè€ƒè™‘ä½¿ç”¨ä¾èµ–æ³¨å…¥æˆ–æ¥å£æŠ½è±¡",
                            details={"modules": [module_a, module_b]},
                        ),
                    )

    def _analyze_coupling(self):
        """åˆ†ææ¨¡å—è€¦åˆåº¦"""
        for module_name, info in self.module_info.items():
            # è®¡ç®—ä¼ å…¥è€¦åˆï¼ˆè¢«å¤šå°‘æ¨¡å—ä¾èµ–ï¼‰
            fan_in = len(
                [
                    m
                    for m in self.module_info.keys()
                    if module_name in self.module_info[m]["imports"]
                ],
            )

            # è®¡ç®—ä¼ å‡ºè€¦åˆï¼ˆä¾èµ–å¤šå°‘æ¨¡å—ï¼‰
            fan_out = len(
                [imp for imp in info["imports"] if imp.startswith("aiculture")],
            )

            # é«˜è€¦åˆè­¦å‘Š
            if fan_out > 10:
                self.issues.append(
                    ArchitectureIssue(
                        file_path=info["file_path"],
                        issue_type="high_coupling",
                        severity="medium",
                        description=f"æ¨¡å— {module_name} ä¾èµ–è¿‡å¤šæ¨¡å— ({fan_out})",
                        suggestion="è€ƒè™‘æ‹†åˆ†æ¨¡å—æˆ–ä½¿ç”¨ä¾èµ–æ³¨å…¥å‡å°‘è€¦åˆ",
                        details={"fan_out": fan_out, "fan_in": fan_in},
                    ),
                )

            if fan_in > 15:
                self.issues.append(
                    ArchitectureIssue(
                        file_path=info["file_path"],
                        issue_type="high_fan_in",
                        severity="medium",
                        description=f"æ¨¡å— {module_name} è¢«è¿‡å¤šæ¨¡å—ä¾èµ– ({fan_in})",
                        suggestion="è€ƒè™‘æ‹†åˆ†æ¨¡å—æˆ–æå–å…¬å…±æ¥å£",
                        details={"fan_out": fan_out, "fan_in": fan_in},
                    ),
                )

    def _check_single_responsibility(self):
        """æ£€æŸ¥å•ä¸€èŒè´£åŸåˆ™"""
        for _module_name, info in self.module_info.items():
            classes = info["classes"]
            info["functions"]

            # æ£€æŸ¥ç±»çš„èŒè´£
            for class_info in classes:
                methods = class_info["methods"]
                if len(methods) > 20:
                    self.issues.append(
                        ArchitectureIssue(
                            file_path=info["file_path"],
                            issue_type="too_many_responsibilities",
                            severity="medium",
                            description=f"ç±» {class_info['name']} æ–¹æ³•è¿‡å¤š ({len(methods)})ï¼Œå¯èƒ½è¿åå•ä¸€èŒè´£åŸåˆ™",
                            suggestion="è€ƒè™‘å°†ç±»æ‹†åˆ†ä¸ºå¤šä¸ªæ›´å°çš„ç±»",
                            details={
                                "class_name": class_info["name"],
                                "method_count": len(methods),
                            },
                        ),
                    )

                # æ£€æŸ¥æ–¹æ³•åçš„ä¸€è‡´æ€§ï¼ˆåˆ¤æ–­èŒè´£æ˜¯å¦å•ä¸€ï¼‰
                method_verbs = []
                for method in methods:
                    if "_" in method:
                        verb = method.split("_")[0]
                        method_verbs.append(verb)

                if len(set(method_verbs)) > 5:  # åŠ¨è¯ç§ç±»è¿‡å¤š
                    self.issues.append(
                        ArchitectureIssue(
                            file_path=info["file_path"],
                            issue_type="mixed_responsibilities",
                            severity="low",
                            description=f"ç±» {class_info['name']} çš„æ–¹æ³•æ¶‰åŠå¤šç§æ“ä½œç±»å‹",
                            suggestion="è€ƒè™‘æŒ‰åŠŸèƒ½èŒè´£é‡æ–°ç»„ç»‡ç±»çš„æ–¹æ³•",
                            details={
                                "class_name": class_info["name"],
                                "verb_types": list(set(method_verbs)),
                            },
                        ),
                    )

    def _analyze_interfaces(self):
        """åˆ†ææ¥å£è®¾è®¡"""
        for _module_name, info in self.module_info.items():
            classes = info["classes"]

            for class_info in classes:
                # æ£€æŸ¥æ˜¯å¦æœ‰æŠ½è±¡åŸºç±»
                if class_info["name"].endswith("Base") or class_info["name"].startswith(
                    "Abstract",
                ):
                    # æ£€æŸ¥æ˜¯å¦æœ‰æŠ½è±¡æ–¹æ³•
                    abstract_methods = [
                        m for m in class_info["methods"] if m.startswith("_")
                    ]
                    if len(abstract_methods) == 0:
                        self.issues.append(
                            ArchitectureIssue(
                                file_path=info["file_path"],
                                issue_type="missing_abstract_methods",
                                severity="low",
                                description=f"æŠ½è±¡ç±» {class_info['name']} æ²¡æœ‰æŠ½è±¡æ–¹æ³•",
                                suggestion="ä¸ºæŠ½è±¡ç±»æ·»åŠ æŠ½è±¡æ–¹æ³•æˆ–é‡æ–°è€ƒè™‘ç±»çš„è®¾è®¡",
                                details={"class_name": class_info["name"]},
                            ),
                        )

                # æ£€æŸ¥å…¬å…±æ¥å£çš„ä¸€è‡´æ€§
                public_methods = [
                    m for m in class_info["methods"] if not m.startswith("_")
                ]
                if len(public_methods) > 15:
                    self.issues.append(
                        ArchitectureIssue(
                            file_path=info["file_path"],
                            issue_type="large_interface",
                            severity="medium",
                            description=f"ç±» {class_info['name']} å…¬å…±æ¥å£è¿‡å¤§ ({len(public_methods)} ä¸ªæ–¹æ³•)",
                            suggestion="è€ƒè™‘æ‹†åˆ†æ¥å£æˆ–ä½¿ç”¨ç»„åˆæ¨¡å¼",
                            details={
                                "class_name": class_info["name"],
                                "public_method_count": len(public_methods),
                            },
                        ),
                    )

    def _check_dependency_inversion(self):
        """æ£€æŸ¥ä¾èµ–å€’ç½®åŸåˆ™"""
        for module_name, info in self.module_info.items():
            imports = info["imports"]

            # æ£€æŸ¥æ˜¯å¦ç›´æ¥ä¾èµ–å…·ä½“å®ç°è€ŒéæŠ½è±¡
            concrete_dependencies = []
            for imp in imports:
                if imp.startswith("aiculture"):
                    # ç®€å•å¯å‘å¼ï¼šå¦‚æœå¯¼å…¥çš„æ¨¡å—ååŒ…å«å…·ä½“å®ç°çš„è¯æ±‡
                    concrete_indicators = [
                        "manager",
                        "handler",
                        "processor",
                        "executor",
                        "worker",
                    ]
                    if any(
                        indicator in imp.lower() for indicator in concrete_indicators
                    ):
                        concrete_dependencies.append(imp)

            if len(concrete_dependencies) > 5:
                self.issues.append(
                    ArchitectureIssue(
                        file_path=info["file_path"],
                        issue_type="concrete_dependency",
                        severity="low",
                        description=f"æ¨¡å— {module_name} ä¾èµ–è¿‡å¤šå…·ä½“å®ç°",
                        suggestion="è€ƒè™‘å¼•å…¥æŠ½è±¡æ¥å£ï¼Œä¾èµ–æŠ½è±¡è€Œéå…·ä½“å®ç°",
                        details={"concrete_dependencies": concrete_dependencies},
                    ),
                )

    def _should_skip_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦è·³è¿‡æ–‡ä»¶"""
        skip_dirs = {"venv", "__pycache__", ".git", "node_modules", ".pytest_cache"}
        return any(part in skip_dirs for part in file_path.parts)

    def _get_module_name(self, file_path: Path) -> str:
        """è·å–æ¨¡å—å"""
        relative_path = file_path.relative_to(self.project_path)
        return (
            str(relative_path).replace("/", ".").replace("\\", ".").replace(".py", "")
        )

    def _extract_imports(self, tree: ast.AST) -> list[str]:
        """æå–å¯¼å…¥ä¿¡æ¯"""
        imports = []
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(node.module)
        return imports

    def _extract_classes(self, tree: ast.AST) -> list[dict[str, Any]]:
        """æå–ç±»ä¿¡æ¯"""
        classes = []
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                methods = [n.name for n in node.body if isinstance(n, ast.FunctionDef)]
                classes.append(
                    {
                        "name": node.name,
                        "methods": methods,
                        "base_classes": [
                            base.id for base in node.bases if isinstance(base, ast.Name)
                        ],
                    },
                )
        return classes

    def _extract_functions(self, tree: ast.AST) -> list[str]:
        """æå–å‡½æ•°ä¿¡æ¯"""
        functions = []
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef) and not isinstance(
                node.parent if hasattr(node, "parent") else None,
                ast.ClassDef,
            ):
                functions.append(node.name)
        return functions

    def _generate_architecture_report(self) -> dict[str, Any]:
        """ç”Ÿæˆæ¶æ„åˆ†ææŠ¥å‘Š"""
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
        by_severity = defaultdict(list)
        for issue in self.issues:
            by_severity[issue.severity].append(issue)

        # æŒ‰ç±»å‹åˆ†ç»„
        by_type = defaultdict(list)
        for issue in self.issues:
            by_type[issue.issue_type].append(issue)

        # è®¡ç®—æ¶æ„æŒ‡æ ‡
        total_modules = len(self.module_info)
        total_dependencies = sum(len(deps) for deps in self.dependencies.values())
        avg_coupling = total_dependencies / max(total_modules, 1)

        return {
            "total_issues": len(self.issues),
            "by_severity": dict(by_severity),
            "by_type": dict(by_type),
            "metrics": {
                "total_modules": total_modules,
                "total_dependencies": total_dependencies,
                "average_coupling": avg_coupling,
                "circular_dependencies": len(
                    [i for i in self.issues if i.issue_type == "circular_dependency"],
                ),
            },
            "summary": {
                "high_severity": len(by_severity["high"]),
                "medium_severity": len(by_severity["medium"]),
                "low_severity": len(by_severity["low"]),
            },
        }


def main():
    """ä¸»å‡½æ•°"""
    analyzer = ArchitectureAnalyzer(Path())
    report = analyzer.analyze_architecture()

    print("\nğŸ—ï¸ æ¶æ„è®¾è®¡åˆ†ææŠ¥å‘Š")
    print("=" * 50)

    metrics = report["metrics"]
    summary = report["summary"]

    print(f"æ€»æ¨¡å—æ•°: {metrics['total_modules']}")
    print(f"æ€»ä¾èµ–å…³ç³»: {metrics['total_dependencies']}")
    print(f"å¹³å‡è€¦åˆåº¦: {metrics['average_coupling']:.2f}")
    print(f"å¾ªç¯ä¾èµ–: {metrics['circular_dependencies']} ä¸ª")
    print()

    print(f"æ¶æ„é—®é¢˜æ€»æ•°: {report['total_issues']}")
    print(f"é«˜ä¸¥é‡æ€§: {summary['high_severity']} ä¸ª")
    print(f"ä¸­ç­‰ä¸¥é‡æ€§: {summary['medium_severity']} ä¸ª")
    print(f"ä½ä¸¥é‡æ€§: {summary['low_severity']} ä¸ª")
    print()

    print("ğŸ” æŒ‰é—®é¢˜ç±»å‹åˆ†ç»„:")
    for issue_type, issues in report["by_type"].items():
        print(f"  {issue_type}: {len(issues)} ä¸ª")

    print("\nğŸš¨ é«˜ä¸¥é‡æ€§é—®é¢˜è¯¦æƒ…:")
    high_issues = report["by_severity"].get("high", [])
    for i, issue in enumerate(high_issues[:5], 1):
        print(f"  {i}. {issue.file_path}")
        print(f"     {issue.description}")
        print(f"     å»ºè®®: {issue.suggestion}")
        print()

    if len(high_issues) > 5:
        print(f"  ... è¿˜æœ‰ {len(high_issues) - 5} ä¸ªé«˜ä¸¥é‡æ€§é—®é¢˜")

    return report


if __name__ == "__main__":
    main()
