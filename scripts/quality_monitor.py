#!/usr/bin/env python3
"""
AICultureKit å®æ—¶è´¨é‡ç›‘æ§ç³»ç»Ÿ
ç›‘æ§ä»£ç è´¨é‡å˜åŒ–ï¼Œè‡ªåŠ¨ç”ŸæˆæŠ¥å‘Šå’Œé€šçŸ¥
"""

import json
import sqlite3
import subprocess
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict


class QualityMonitor:
    """è´¨é‡ç›‘æ§å™¨"""

    def __init__(self, project_path: Path = None) -> None:
        """TODO: æ·»åŠ å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²"""
        self.project_path = project_path or Path.cwd()
        self.db_path = self.project_path / ".quality_history.db"
        self.init_database()

    def init_database(self) -> None:
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            '''
            CREATE TABLE IF NOT EXISTS quality_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                commit_hash TEXT,
                test_count INTEGER,
                test_passed INTEGER,
                coverage_percent REAL,
                flake8_issues INTEGER,
                mypy_errors INTEGER,
                file_count INTEGER,
                line_count INTEGER,
                quality_score INTEGER
            )
        '''
        )

        cursor.execute(
            '''
            CREATE TABLE IF NOT EXISTS quality_alerts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                alert_type TEXT NOT NULL,
                message TEXT NOT NULL,
                severity TEXT NOT NULL,
                resolved BOOLEAN DEFAULT FALSE
            )
        '''
        )

        conn.commit()
        conn.close()

    def run_command(self, cmd: str) -> tuple[bool, str]:
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            result = subprocess.run(
                cmd,
                shell=True,  # TODO:    è€ƒè™‘ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼, capture_output=True, text=True, cwd=self.project_path
            )
            return result.returncode == 0, result.stdout.strip()
        except Exception as e:
            return False, str(e)

    def collect_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†å½“å‰çš„è´¨é‡æŒ‡æ ‡"""
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "commit_hash": "",
            "test_count": 0,
            "test_passed": 0,
            "coverage_percent": 0.0,
            "flake8_issues": 0,
            "mypy_errors": 0,
            "file_count": 0,
            "line_count": 0,
            "quality_score": 0,
        }

        # Gitä¿¡æ¯
        success, output = self.run_command("git rev-parse --short HEAD")
        if success:
            metrics["commit_hash"] = output

        # æµ‹è¯•ä¿¡æ¯
        success, output = self.run_command(
            "python -m pytest --tb=no -q --json-report --json-report-file=temp_test_report.json"
        )
        if success and Path("temp_test_report.json").exists():
            try:
                with open("temp_test_report.json", "r") as f:
                    test_data = json.load(f)
                metrics["test_count"] = test_data.get("summary", {}).get("total", 0)
                metrics["test_passed"] = test_data.get("summary", {}).get("passed", 0)
                Path("temp_test_report.json").unlink()  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            except Exception:
                pass  # TODO:   æ·»åŠ é€‚å½“çš„å¼‚å¸¸å¤„ç†
        # è¦†ç›–ç‡ä¿¡æ¯
        success, output = self.run_command(
            "python -m pytest --cov=aiculture --cov-report=json --tb=no -q"
        )
        if success and Path("coverage.json").exists():
            try:
                with open("coverage.json", "r") as f:
                    cov_data = json.load(f)
                metrics["coverage_percent"] = cov_data.get("totals", {}).get("percent_covered", 0)
            except Exception:
                pass  # TODO:   æ·»åŠ é€‚å½“çš„å¼‚å¸¸å¤„ç†
        # Flake8é—®é¢˜
        success, output = self.run_command("flake8 . --count")
        if success and output.isdigit():
            metrics["flake8_issues"] = int(output)

        # MyPyé”™è¯¯
        success, output = self.run_command("mypy aiculture --ignore-missing-imports")
        if success:
            metrics["mypy_errors"] = output.count("error:")

        # ä»£ç ç»Ÿè®¡
        success, output = self.run_command("find aiculture -name '*.py' | wc -l")
        if success and output.isdigit():
            metrics["file_count"] = int(output)

        success, output = self.run_command(
            "find aiculture -name '*.py' -exec wc -l {} + | tail -1 | awk '{print $1}'"
        )
        if success and output.isdigit():
            metrics["line_count"] = int(output)

        # è®¡ç®—è´¨é‡åˆ†æ•°
        metrics["quality_score"] = self.calculate_quality_score(metrics)

        return metrics

    def calculate_quality_score(self, metrics: Dict[str, Any]) -> int:
        """è®¡ç®—è´¨é‡åˆ†æ•°"""
        score = 100

        # æµ‹è¯•å¤±è´¥æ‰£åˆ†
        failed_tests = metrics["test_count"] - metrics["test_passed"]
        score -= failed_tests * 10

        # è¦†ç›–ç‡ä½æ‰£åˆ†
        if metrics["coverage_percent"] < 80:
            score -= (80 - metrics["coverage_percent"]) * 0.5

        # ä»£ç è´¨é‡é—®é¢˜æ‰£åˆ†
        score -= metrics["flake8_issues"] * 2
        score -= metrics["mypy_errors"] * 1

        return max(0, int(score))

    def save_metrics(self, metrics: Dict[str, Any]) -> None:
        """ä¿å­˜æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            '''
            INSERT INTO quality_metrics
            (timestamp, commit_hash, test_count, test_passed, coverage_percent,
             flake8_issues, mypy_errors, file_count, line_count, quality_score)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''',
            (
                metrics["timestamp"],
                metrics["commit_hash"],
                metrics["test_count"],
                metrics["test_passed"],
                metrics["coverage_percent"],
                metrics["flake8_issues"],
                metrics["mypy_errors"],
                metrics["file_count"],
                metrics["line_count"],
                metrics["quality_score"],
            ),
        )

        conn.commit()
        conn.close()

    def check_quality_alerts(self, current_metrics: Dict[str, Any]) -> None:
        """æ£€æŸ¥è´¨é‡è­¦æŠ¥"""
        alerts = []

        # è·å–å†å²æ•°æ®è¿›è¡Œå¯¹æ¯”
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute(
            '''
            SELECT * FROM quality_metrics
            ORDER BY timestamp DESC
            LIMIT 2
        '''
        )

        rows = cursor.fetchall()
        if len(rows) >= 2:
            prev_metrics = dict(zip([col[0] for col in cursor.description], rows[1]))

            # æ£€æŸ¥è´¨é‡ä¸‹é™
            if current_metrics["quality_score"] < prev_metrics["quality_score"] - 5:
                alerts.append(
                    {
                        "type": "quality_decline",
                        "message": f"è´¨é‡åˆ†æ•°ä¸‹é™: {prev_metrics['quality_score']} â†’ {current_metrics['quality_score']}",
                        "severity": "warning",
                    }
                )

            # æ£€æŸ¥æµ‹è¯•å¤±è´¥å¢åŠ 
            prev_failed = prev_metrics["test_count"] - prev_metrics["test_passed"]
            curr_failed = current_metrics["test_count"] - current_metrics["test_passed"]
            if curr_failed > prev_failed:
                alerts.append(
                    {
                        "type": "test_regression",
                        "message": f"æµ‹è¯•å¤±è´¥å¢åŠ : {prev_failed} â†’ {curr_failed}",
                        "severity": "error",
                    }
                )

            # æ£€æŸ¥è¦†ç›–ç‡ä¸‹é™
            if current_metrics["coverage_percent"] < prev_metrics["coverage_percent"] - 2:
                alerts.append(
                    {
                        "type": "coverage_decline",
                        "message": f"è¦†ç›–ç‡ä¸‹é™: {prev_metrics['coverage_percent']:.1f}% â†’ {current_metrics['coverage_percent']:.1f}%",
                        "severity": "warning",
                    }
                )

        # æ£€æŸ¥ç»å¯¹é˜ˆå€¼
        if current_metrics["coverage_percent"] < 30:
            alerts.append(
                {
                    "type": "low_coverage",
                    "message": f"ä»£ç è¦†ç›–ç‡è¿‡ä½: {current_metrics['coverage_percent']:.1f}%",
                    "severity": "warning",
                }
            )

        if current_metrics["test_count"] - current_metrics["test_passed"] > 0:
            alerts.append(
                {
                    "type": "test_failures",
                    "message": f"æœ‰ {current_metrics['test_count'] - current_metrics['test_passed']} ä¸ªæµ‹è¯•å¤±è´¥",
                    "severity": "error",
                }
            )

        # ä¿å­˜è­¦æŠ¥
        for alert in alerts:
            cursor.execute(
                '''
                INSERT INTO quality_alerts (timestamp, alert_type, message, severity)
                VALUES (?, ?, ?, ?)
            ''',
                (
                    current_metrics["timestamp"],
                    alert["type"],
                    alert["message"],
                    alert["severity"],
                ),
            )

        conn.commit()
        conn.close()

        return alerts

    def generate_trend_report(self, days: int = 7) -> str:
        """ç”Ÿæˆè¶‹åŠ¿æŠ¥å‘Š"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        since_date = (datetime.now() - timedelta(days=days)).isoformat()
        cursor.execute(
            '''
            SELECT * FROM quality_metrics
            WHERE timestamp > ?
            ORDER BY timestamp DESC
        ''',
            (since_date,),
        )

        rows = cursor.fetchall()
        columns = [col[0] for col in cursor.description]

        if not rows:
            return "ğŸ“Š æš‚æ— å†å²æ•°æ®"

        # è®¡ç®—è¶‹åŠ¿
        latest = dict(zip(columns, rows[0]))
        oldest = dict(zip(columns, rows[-1]))

        report = f"""
ğŸ“Š AICultureKit è´¨é‡è¶‹åŠ¿æŠ¥å‘Š (æœ€è¿‘{days}å¤©)
{'='*50}

ğŸ“ˆ æ€»ä½“è¶‹åŠ¿:
  è´¨é‡åˆ†æ•°: {oldest['quality_score']} â†’ {latest['quality_score']} ({latest['quality_score'] - oldest['quality_score']:+d})
  æµ‹è¯•é€šè¿‡: {oldest['test_passed']}/{oldest['test_count']} â†’ {latest['test_passed']}/{latest['test_count']}
  ä»£ç è¦†ç›–ç‡: {oldest['coverage_percent']:.1f}% â†’ {latest['coverage_percent']:.1f}% ({latest['coverage_percent'] - oldest['coverage_percent']:+.1f}%)
  ä»£ç è¡Œæ•°: {oldest['line_count']} â†’ {latest['line_count']} ({latest['line_count'] - oldest['line_count']:+d})

ğŸ” è´¨é‡é—®é¢˜:
  Flake8é—®é¢˜: {oldest['flake8_issues']} â†’ {latest['flake8_issues']} ({latest['flake8_issues'] - oldest['flake8_issues']:+d})
  MyPyé”™è¯¯: {oldest['mypy_errors']} â†’ {latest['mypy_errors']} ({latest['mypy_errors'] - oldest['mypy_errors']:+d})

ğŸ“… æ•°æ®ç‚¹æ•°: {len(rows)}
ğŸ• æœ€åæ›´æ–°: {latest['timestamp']}
"""

        conn.close()
        return report

    def monitor_once(self) -> Dict[str, Any]:
        """æ‰§è¡Œä¸€æ¬¡ç›‘æ§"""
        print("ğŸ” æ”¶é›†è´¨é‡æŒ‡æ ‡...")
        metrics = self.collect_metrics()

        print("ğŸ’¾ ä¿å­˜æŒ‡æ ‡...")
        self.save_metrics(metrics)

        print("ğŸš¨ æ£€æŸ¥è­¦æŠ¥...")
        alerts = self.check_quality_alerts(metrics)

        # æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“Š å½“å‰è´¨é‡æŒ‡æ ‡:")
        print(f"  è´¨é‡åˆ†æ•°: {metrics['quality_score']}/100")
        print(f"  æµ‹è¯•é€šè¿‡: {metrics['test_passed']}/{metrics['test_count']}")
        print(f"  ä»£ç è¦†ç›–ç‡: {metrics['coverage_percent']:.1f}%")
        print(f"  ä»£ç é—®é¢˜: {metrics['flake8_issues']} flake8, {metrics['mypy_errors']} mypy")

        if alerts:
            print(f"\nğŸš¨ å‘ç° {len(alerts)} ä¸ªè­¦æŠ¥:")
            for alert in alerts:
                emoji = "ğŸ”´" if alert["severity"] == "error" else "ğŸŸ¡"
                print(f"  {emoji} {alert['message']}")
        else:
            print("\nâœ… æ— è´¨é‡è­¦æŠ¥")

        return {"metrics": metrics, "alerts": alerts}


def watch_mode(monitor: QualityMonitor, interval: int = 300) -> None:
    """ç›‘æ§æ¨¡å¼ï¼Œå®šæœŸæ£€æŸ¥è´¨é‡"""
    print(f"ğŸ”„ å¯åŠ¨ç›‘æ§æ¨¡å¼ï¼Œæ¯ {interval} ç§’æ£€æŸ¥ä¸€æ¬¡...")

    try:
        while True:
            result = monitor.monitor_once()

            # å¦‚æœæœ‰ä¸¥é‡è­¦æŠ¥ï¼Œç«‹å³é€šçŸ¥
            critical_alerts = [a for a in result["alerts"] if a["severity"] == "error"]
            if critical_alerts:
                print(f"\nğŸš¨ å‘ç° {len(critical_alerts)} ä¸ªä¸¥é‡é—®é¢˜ï¼Œå»ºè®®ç«‹å³å¤„ç†ï¼")

            print(f"\nâ° ä¸‹æ¬¡æ£€æŸ¥æ—¶é—´: {datetime.now() + timedelta(seconds=interval)}")
            time.sleep(interval)

    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç›‘æ§å·²åœæ­¢")


def main() -> None:
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="AICultureKit è´¨é‡ç›‘æ§ç³»ç»Ÿ")
    parser.add_argument("--watch", action="store_true", help="å¯åŠ¨ç›‘æ§æ¨¡å¼")
    parser.add_argument("--interval", type=int, default=300, help="ç›‘æ§é—´éš”(ç§’)")
    parser.add_argument("--trend", type=int, default=7, help="è¶‹åŠ¿æŠ¥å‘Šå¤©æ•°")

    args = parser.parse_args()

    monitor = QualityMonitor()

    if args.watch:
        watch_mode(monitor, args.interval)
    else:
        # æ‰§è¡Œä¸€æ¬¡ç›‘æ§
        result = monitor.monitor_once()

        # ç”Ÿæˆè¶‹åŠ¿æŠ¥å‘Š
        print("\n" + "=" * 50)
        trend_report = monitor.generate_trend_report(args.trend)
        print(trend_report)


if __name__ == "__main__":
    main()
