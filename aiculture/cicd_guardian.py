"""CI/CDæ™ºèƒ½å®ˆæŠ¤ç³»ç»Ÿ
å…¨é¢æ£€æµ‹å’Œé¢„é˜²æ„å»ºå¤±è´¥çš„æ™ºèƒ½åŒ–è§£å†³æ–¹æ¡ˆ
"""

import subprocess
import time
from dataclasses import dataclass
from enum import Enum
from pathlib import Path
from typing import Any

import requests
import yaml

# å¸¸é‡å®šä¹‰
MINUTES_PER_HOUR = 60


class RiskLevel(Enum):
    """é£é™©ç­‰çº§"""

    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


@dataclass
class BuildRisk:
    """æ„å»ºé£é™©"""

    category: str
    risk_level: RiskLevel
    description: str
    impact: str
    prevention: str
    auto_fix: bool = False


class CICDGuardian:
    """CI/CDæ™ºèƒ½å®ˆæŠ¤ç³»ç»Ÿ"""

    def __init__(self, project_path: str = ".") -> None:
        """å†…éƒ¨æ–¹æ³•ï¼š init"""
        self.project_path = Path(project_path)
        self.risks: list[BuildRisk] = []
        self.docker_client = None
        self.config = self._load_config()

    def _load_config(self) -> dict:
        """åŠ è½½é…ç½®"""
        config_file = self.project_path / "aiculture.yaml"
        if config_file.exists():
            with open(config_file, encoding="utf-8") as f:
                return yaml.safe_load(f)
        return {}

    def comprehensive_health_check(self) -> dict[str, Any]:
        """å…¨é¢å¥åº·æ£€æŸ¥"""
        print("ğŸ” å¼€å§‹CI/CDæ„å»ºå¥åº·æ£€æŸ¥...")

        self.risks.clear()

        # 1. ç¯å¢ƒæ£€æŸ¥
        self._check_environment()

        # 2. ä¾èµ–æ£€æŸ¥
        self._check_dependencies()

        # 3. ç½‘ç»œæ£€æŸ¥
        self._check_network()

        # 4. èµ„æºæ£€æŸ¥
        self._check_resources()

        # 5. é…ç½®æ£€æŸ¥
        self._check_configuration()

        # 6. ä»£ç è´¨é‡æ£€æŸ¥
        self._check_code_quality()

        # 7. å®‰å…¨æ£€æŸ¥
        self._check_security()

        return self._generate_report()

    def _check_environment(self) -> Any:
        """ç¯å¢ƒæ£€æŸ¥"""
        print("ğŸ“¦ æ£€æŸ¥ç¯å¢ƒé…ç½®...")

        # æ£€æŸ¥DockerfileåŸºç¡€é•œåƒ
        dockerfile = self.project_path / "Dockerfile"
        if dockerfile.exists():
            with open(dockerfile) as f:
                content = f.read()

            # æ£€æŸ¥åŸºç¡€é•œåƒç‰ˆæœ¬å›ºå®š
            if "FROM python:latest" in content or "FROM ubuntu:latest" in content:
                self.risks.append(
                    BuildRisk(
                        category="environment",
                        risk_level=RiskLevel.HIGH,
                        description="ä½¿ç”¨äº†ä¸ç¨³å®šçš„latestæ ‡ç­¾",
                        impact="åŸºç¡€é•œåƒæ›´æ–°å¯èƒ½å¯¼è‡´æ„å»ºå¤±è´¥",
                        prevention="ä½¿ç”¨å›ºå®šç‰ˆæœ¬å·ï¼Œå¦‚ python:3.10-slim",
                        auto_fix=True,
                    ),
                )

            # æ£€æŸ¥å¤šé˜¶æ®µæ„å»º
            if "FROM" in content and content.count("FROM") == 1:
                self.risks.append(
                    BuildRisk(
                        category="environment",
                        risk_level=RiskLevel.MEDIUM,
                        description="æœªä½¿ç”¨å¤šé˜¶æ®µæ„å»º",
                        impact="é•œåƒä½“ç§¯å¤§ï¼Œæ„å»ºæ—¶é—´é•¿",
                        prevention="é‡‡ç”¨å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–é•œåƒå¤§å°",
                        auto_fix=False,
                    ),
                )

        # æ£€æŸ¥ç³»ç»Ÿä¾èµ–
        if "apt-get install" in content and "apt-get clean" not in content:
            self.risks.append(
                BuildRisk(
                    category="environment",
                    risk_level=RiskLevel.MEDIUM,
                    description="æœªæ¸…ç†aptç¼“å­˜",
                    impact="é•œåƒä½“ç§¯å¢å¤§",
                    prevention="æ·»åŠ  rm -rf /var/lib/apt/lists/*",
                    auto_fix=True,
                ),
            )

    def _check_dependencies(self) -> Any:
        """ä¾èµ–æ£€æŸ¥"""
        print("ğŸ“‹ æ£€æŸ¥ä¾èµ–ç®¡ç†...")

        # æ£€æŸ¥requirements.txt
        req_file = self.project_path / "requirements.txt"
        if req_file.exists():
            with open(req_file) as f:
                content = f.read()

            # æ£€æŸ¥ç‰ˆæœ¬å›ºå®š
            lines = content.strip().split("\n")
            unpinned = []
            for line in lines:
                if line.strip() and not line.startswith("#"):
                    if ">=" in line or "~=" in line or "^" in line:
                        unpinned.append(line.strip())

            if unpinned:
                self.risks.append(
                    BuildRisk(
                        category="dependencies",
                        risk_level=RiskLevel.HIGH,
                        description=f"å‘ç°{len(unpinned)}ä¸ªæœªå›ºå®šç‰ˆæœ¬çš„ä¾èµ–",
                        impact="ä¾èµ–ç‰ˆæœ¬æ›´æ–°å¯èƒ½å¯¼è‡´æ„å»ºå¤±è´¥",
                        prevention="ä½¿ç”¨ pip freeze ç”Ÿæˆç²¾ç¡®ç‰ˆæœ¬é”å®š",
                        auto_fix=True,
                    ),
                )

        # æ£€æŸ¥ä¾èµ–å®‰å…¨æ€§
        try:
            result = subprocess.run(
                ["safety", "check", "-r", str(req_file)],
                check=False,
                capture_output=True,
                text=True,
                timeout=30,
            )
            if result.returncode != 0:
                self.risks.append(
                    BuildRisk(
                        category="dependencies",
                        risk_level=RiskLevel.CRITICAL,
                        description="å‘ç°ä¾èµ–å®‰å…¨æ¼æ´",
                        impact="å­˜åœ¨å®‰å…¨é£é™©ï¼Œå¯èƒ½è¢«æ‹’ç»éƒ¨ç½²",
                        prevention="æ›´æ–°æœ‰æ¼æ´çš„ä¾èµ–åŒ…",
                        auto_fix=False,
                    ),
                )
        except (subprocess.TimeoutExpired, FileNotFoundError):
            pass

    def _check_network(self) -> Any:
        """ç½‘ç»œæ£€æŸ¥"""
        print("ğŸŒ æ£€æŸ¥ç½‘ç»œè¿é€šæ€§...")

        # æ£€æŸ¥å…³é”®æœåŠ¡è¿é€šæ€§
        critical_urls = [
            "https://pypi.org/simple/",
            "https://registry-1.docker.io/",
            "https://github.com/",
            "https://api.github.com/",
        ]

        failed_connections = []
        for url in critical_urls:
            try:
                response = requests.get(url, timeout=10)
                if response.status_code >= 400:
                    failed_connections.append(url)
            except requests.RequestException:
                failed_connections.append(url)

        if failed_connections:
            self.risks.append(
                BuildRisk(
                    category="network",
                    risk_level=RiskLevel.HIGH,
                    description=f"æ— æ³•è¿æ¥åˆ°å…³é”®æœåŠ¡: {failed_connections}",
                    impact="æ„å»ºè¿‡ç¨‹ä¸­å¯èƒ½ç½‘ç»œå¤±è´¥",
                    prevention="é…ç½®é‡è¯•æœºåˆ¶å’Œå¤‡ç”¨é•œåƒæº",
                    auto_fix=False,
                ),
            )

    def _check_resources(self) -> Any:
        """èµ„æºæ£€æŸ¥"""
        print("ğŸ’¾ æ£€æŸ¥ç³»ç»Ÿèµ„æº...")

        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        import shutil

        total, used, free = shutil.disk_usage(self.project_path)
        free_gb = free // (1024**3)

        if free_gb < 5:
            self.risks.append(
                BuildRisk(
                    category="resources",
                    risk_level=RiskLevel.CRITICAL,
                    description=f"ç£ç›˜ç©ºé—´ä¸è¶³: {free_gb}GB",
                    impact="æ„å»ºè¿‡ç¨‹ä¸­å¯èƒ½ç©ºé—´ä¸è¶³å¤±è´¥",
                    prevention="æ¸…ç†ç£ç›˜ç©ºé—´æˆ–å¢åŠ å­˜å‚¨",
                    auto_fix=False,
                ),
            )
        elif free_gb < 10:
            self.risks.append(
                BuildRisk(
                    category="resources",
                    risk_level=RiskLevel.MEDIUM,
                    description=f"ç£ç›˜ç©ºé—´ç´§å¼ : {free_gb}GB",
                    impact="å¯èƒ½å½±å“æ„å»ºæ€§èƒ½",
                    prevention="å»ºè®®æ¸…ç†ä¸å¿…è¦æ–‡ä»¶",
                    auto_fix=False,
                ),
            )

        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        try:
            with open("/proc/meminfo") as f:
                meminfo = f.read()
            mem_available = (
                int(
                    [line for line in meminfo.split("\n") if "MemAvailable" in line][
                        0
                    ].split()[1],
                )
                // 1024
            )

            if mem_available < 2048:  # å°äº2GB
                self.risks.append(
                    BuildRisk(
                        category="resources",
                        risk_level=RiskLevel.HIGH,
                        description=f"å¯ç”¨å†…å­˜ä¸è¶³: {mem_available}MB",
                        impact="æ„å»ºè¿‡ç¨‹å¯èƒ½å†…å­˜æº¢å‡º",
                        prevention="å…³é—­ä¸å¿…è¦è¿›ç¨‹æˆ–å¢åŠ å†…å­˜",
                        auto_fix=False,
                    ),
                )
        except (FileNotFoundError, IndexError):
            pass  # éLinuxç³»ç»Ÿ

    def _check_configuration(self) -> Any:
        """é…ç½®æ£€æŸ¥"""
        print("âš™ï¸ æ£€æŸ¥é…ç½®æ–‡ä»¶...")

        # æ£€æŸ¥.dockerignore
        dockerignore = self.project_path / ".dockerignore"
        if not dockerignore.exists():
            self.risks.append(
                BuildRisk(
                    category="configuration",
                    risk_level=RiskLevel.MEDIUM,
                    description="ç¼ºå°‘.dockerignoreæ–‡ä»¶",
                    impact="å¯èƒ½å¤åˆ¶ä¸å¿…è¦æ–‡ä»¶ï¼Œå¢åŠ æ„å»ºæ—¶é—´",
                    prevention="åˆ›å»º.dockerignoreæ’é™¤ä¸å¿…è¦æ–‡ä»¶",
                    auto_fix=True,
                ),
            )

        # æ£€æŸ¥CI/CDé…ç½®
        ci_config = self.project_path / ".github" / "workflows"
        if ci_config.exists():
            for workflow_file in ci_config.glob("*.yml"):
                with open(workflow_file) as f:
                    workflow = yaml.safe_load(f)

                # æ£€æŸ¥è¶…æ—¶è®¾ç½®
                jobs = workflow.get("jobs", {})
                for job_name, job_config in jobs.items():
                    if "timeout-minutes" not in job_config:
                        self.risks.append(
                            BuildRisk(
                                category="configuration",
                                risk_level=RiskLevel.MEDIUM,
                                description=f"ä½œä¸š {job_name} ç¼ºå°‘è¶…æ—¶è®¾ç½®",
                                impact="å¯èƒ½å¯¼è‡´æ— é™ç­‰å¾…",
                                prevention="æ·»åŠ  timeout-minutes é…ç½®",
                                auto_fix=True,
                            ),
                        )

    def _check_code_quality(self) -> Any:
        """ä»£ç è´¨é‡æ£€æŸ¥"""
        print("ğŸ“ æ£€æŸ¥ä»£ç è´¨é‡...")

        # æ£€æŸ¥æ˜¯å¦æœ‰AIæ–‡åŒ–é…ç½®
        if not (self.project_path / "aiculture.yaml").exists():
            self.risks.append(
                BuildRisk(
                    category="code_quality",
                    risk_level=RiskLevel.MEDIUM,
                    description="ç¼ºå°‘AIå¼€å‘æ–‡åŒ–é…ç½®",
                    impact="æ— æ³•è‡ªåŠ¨è´¨é‡æ£€æŸ¥å’Œä¿®å¤",
                    prevention="è¿è¡Œ aiculture enable-culture å¯ç”¨",
                    auto_fix=True,
                ),
            )

    def _check_security(self) -> Any:
        """å®‰å…¨æ£€æŸ¥"""
        print("ğŸ”’ æ£€æŸ¥å®‰å…¨é…ç½®...")

        # æ£€æŸ¥å¯†é’¥æ³„éœ²
        secret_patterns = [
            r'password\s*=\s*["\'][^"\']+["\']',
            r'api_key\s*=\s*["\'][^"\']+["\']',
            r'secret\s*=\s*["\'][^"\']+["\']',
            r'token\s*=\s*["\'][^"\']+["\']',
        ]

        import re

        for py_file in self.project_path.rglob("*.py"):
            if "venv" in str(py_file) or ".git" in str(py_file):
                continue

            try:
                with open(py_file, encoding="utf-8") as f:
                    content = f.read()

                for pattern in secret_patterns:
                    if re.search(pattern, content, re.IGNORECASE):
                        self.risks.append(
                            BuildRisk(
                                category="security",
                                risk_level=RiskLevel.CRITICAL,
                                description=f"åœ¨ {py_file} ä¸­å‘ç°å¯èƒ½çš„ç¡¬ç¼–ç å¯†é’¥",
                                impact="æ•æ„Ÿä¿¡æ¯æ³„éœ²é£é™©",
                                prevention="ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†æœåŠ¡",
                                auto_fix=False,
                            ),
                        )
                        break
            except Exception:
                continue

    def _generate_report(self) -> dict[str, Any]:
        """ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š"""
        critical_risks = [r for r in self.risks if r.risk_level == RiskLevel.CRITICAL]
        high_risks = [r for r in self.risks if r.risk_level == RiskLevel.HIGH]
        medium_risks = [r for r in self.risks if r.risk_level == RiskLevel.MEDIUM]
        low_risks = [r for r in self.risks if r.risk_level == RiskLevel.LOW]

        # è®¡ç®—é£é™©è¯„åˆ†
        score = 100
        score -= len(critical_risks) * 25
        score -= len(high_risks) * 15
        score -= len(medium_risks) * 8
        score -= len(low_risks) * 3
        score = max(0, score)

        return {
            "timestamp": time.time(),
            "score": score,
            "risk_summary": {
                "critical": len(critical_risks),
                "high": len(high_risks),
                "medium": len(medium_risks),
                "low": len(low_risks),
                "total": len(self.risks),
            },
            "risks": [
                {
                    "category": risk.category,
                    "risk_level": risk.risk_level.value,
                    "description": risk.description,
                    "impact": risk.impact,
                    "prevention": risk.prevention,
                    "auto_fix": risk.auto_fix,
                }
                for risk in self.risks
            ],
            "recommendation": self._get_recommendation(score),
        }

    def _get_recommendation(self, score: int) -> str:
        """è·å–å»ºè®®"""
        if score >= 90:
            return "âœ… æ„å»ºé£é™©å¾ˆä½ï¼Œå¯ä»¥å®‰å…¨éƒ¨ç½²"
        if score >= 70:
            return "âš ï¸ å­˜åœ¨ä¸­ç­‰é£é™©ï¼Œå»ºè®®ä¿®å¤åéƒ¨ç½²"
        if score >= 50:
            return "ğŸš¨ å­˜åœ¨é«˜é£é™©ï¼Œå¿…é¡»ä¿®å¤å…³é”®é—®é¢˜"
        return "ğŸ”¥ é£é™©æé«˜ï¼Œç¦æ­¢éƒ¨ç½²ï¼Œéœ€è¦å…¨é¢ä¿®å¤"

    def auto_fix_issues(self) -> dict[str, Any]:
        """è‡ªåŠ¨ä¿®å¤é—®é¢˜"""
        print("ğŸ”§ å¼€å§‹è‡ªåŠ¨ä¿®å¤é—®é¢˜...")

        fixed_issues = []
        failed_fixes = []

        for risk in self.risks:
            if risk.auto_fix:
                try:
                    if self._fix_issue(risk):
                        fixed_issues.append(risk.description)
                    else:
                        failed_fixes.append(risk.description)
                except Exception as e:
                    raise e
                    failed_fixes.append(f"{risk.description}: {e!s}")

        return {
            "fixed": fixed_issues,
            "failed": failed_fixes,
            "success_rate": (
                len(fixed_issues) / (len(fixed_issues) + len(failed_fixes))
                if (len(fixed_issues) + len(failed_fixes)) > 0
                else 1.0
            ),
        }

    def _fix_issue(self, risk: BuildRisk) -> bool:
        """ä¿®å¤å…·ä½“é—®é¢˜"""
        if "latestæ ‡ç­¾" in risk.description:
            return self._fix_dockerfile_base_image()
        if "dockerignore" in risk.description:
            return self._create_dockerignore()
        if "æœªå›ºå®šç‰ˆæœ¬" in risk.description:
            return self._fix_requirements_versions()
        if "è¶…æ—¶è®¾ç½®" in risk.description:
            return self._add_workflow_timeouts()
        if "AIå¼€å‘æ–‡åŒ–é…ç½®" in risk.description:
            return self._setup_ai_culture()

        return False

    def _fix_dockerfile_base_image(self) -> bool:
        """ä¿®å¤DockerfileåŸºç¡€é•œåƒ"""
        dockerfile = self.project_path / "Dockerfile"
        if not dockerfile.exists():
            return False

        with open(dockerfile) as f:
            content = f.read()

        # æ›¿æ¢latestæ ‡ç­¾
        content = content.replace("FROM python:latest", "FROM python:3.10-slim")
        content = content.replace("FROM ubuntu:latest", "FROM ubuntu:22.04")

        with open(dockerfile, "w") as f:
            f.write(content)

        return True

    def _create_dockerignore(self) -> bool:
        """åˆ›å»º.dockerignoreæ–‡ä»¶"""
        dockerignore_content = """# Git
.git
.gitignore

# Python
__pycache__
*.pyc
*.pyo
*.pyd
.Python
env
pip-log.txt
pip-delete-this-directory.txt
.tox
.coverage
.coverage.*
.pytest_cache
.cache

# Documentation
docs/
*.md
!README.md

# Development
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Tests
tests/
test_*
*_test.py

# Build
build/
dist/
*.egg-info/
"""

        dockerignore = self.project_path / ".dockerignore"
        with open(dockerignore, "w") as f:
            f.write(dockerignore_content)

        return True

    def _fix_requirements_versions(self) -> bool:
        """ä¿®å¤requirementsç‰ˆæœ¬"""
        req_file = self.project_path / "requirements.txt"
        if not req_file.exists():
            return False

        # ç”Ÿæˆé”å®šç‰ˆæœ¬
        try:
            result = subprocess.run(
                ["pip", "freeze"],
                check=False,
                capture_output=True,
                text=True,
                timeout=MINUTES_PER_HOUR,
            )
            if result.returncode == 0:
                lock_file = self.project_path / "requirements.lock"
                with open(lock_file, "w") as f:
                    f.write(result.stdout)
                return True
        except subprocess.TimeoutExpired:
            pass

        return False

    def _add_workflow_timeouts(self) -> bool:
        """æ·»åŠ å·¥ä½œæµè¶…æ—¶è®¾ç½®"""
        workflows_dir = self.project_path / ".github" / "workflows"
        if not workflows_dir.exists():
            return False

        modified = False
        for workflow_file in workflows_dir.glob("*.yml"):
            with open(workflow_file) as f:
                workflow = yaml.safe_load(f)

            jobs = workflow.get("jobs", {})
            for _job_name, job_config in jobs.items():
                if "timeout-minutes" not in job_config:
                    job_config["timeout-minutes"] = 30
                    modified = True

            if modified:
                with open(workflow_file, "w") as f:
                    yaml.dump(workflow, f, default_flow_style=False)

        return modified

    def _setup_ai_culture(self) -> bool:
        """è®¾ç½®AIå¼€å‘æ–‡åŒ–"""
        try:
            from .auto_setup import setup_ai_culture

            return setup_ai_culture(str(self.project_path))
        except ImportError:
            return False


def run_cicd_health_check(project_path: str = ".") -> dict[str, Any]:
    """è¿è¡ŒCI/CDå¥åº·æ£€æŸ¥"""
    guardian = CICDGuardian(project_path)
    return guardian.comprehensive_health_check()


def auto_fix_cicd_issues(project_path: str = ".") -> dict[str, Any]:
    """è‡ªåŠ¨ä¿®å¤CI/CDé—®é¢˜"""
    guardian = CICDGuardian(project_path)
    guardian.comprehensive_health_check()
    return guardian.auto_fix_issues()
